{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "from carto.datasets import DatasetManager\n",
    "from carto.auth import APIKeyAuthClient\n",
    "import boto3\n",
    "from zipfile import ZipFile\n",
    "from botocore.exceptions import NoCredentialsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of table on Carto where you want to upload data\n",
    "# this should be a table name that is not currently in use\n",
    "dataset_name = 'soc_025a_gender_inequality_index' #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory that you are working in with the path variable\n",
    "# you can use an environmental variable, as we did, or directly enter the directory name as a string\n",
    "# example: path = '/home/cli_029a_vulnerability_to_cc'\n",
    "dir = os.getenv('PROCESSING_DIR')+dataset_name\n",
    "#move to this directory\n",
    "os.chdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new sub-directory within your specified dir called 'data'\n",
    "data_dir = 'data/'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data from the source\n",
    "\n",
    "# insert the url used to download the data from the source website\n",
    "url = 'http://hdr.undp.org/sites/default/files/hdro_statistical_data_table_5.xlsx' #check\n",
    "# read in data to pandas dataframe\n",
    "r = requests.get(url)\n",
    "df = pd.read_excel(io.BytesIO(r.content), encoding='utf8')\n",
    "# save unprocessed source data to put on S3 (below)\n",
    "df.to_excel('data/hdro_statistical_data_table_5.xlsx', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "\n",
    "# drop header rows\n",
    "df = df.iloc[7:] #check\n",
    "\n",
    "# drop columns without data\n",
    "df = df.drop(df.columns.difference(['Unnamed: 0','Table 5. Gender Inequality Index', 'Unnamed: 2','Unnamed: 4',\n",
    "                                    'Unnamed: 6', 'Unnamed: 8','Unnamed: 10','Unnamed: 12', 'Unnamed: 14', \n",
    "                                    'Unnamed: 16', 'Unnamed: 18']), 1) #check\n",
    "\n",
    "#delete rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df.columns = ['HDI rank','Country','2018_GIIvalue', '2018_GIIrank', '2015 Maternal Mortality (per 1000 births)', \n",
    "              '2015-2020 Adolescent birth rate (births per 1,000 women ages 15â€“19)', \n",
    "              '2018 Share of seats in parliament','2010-2018 fem with secondary ed', \n",
    "              '2010-2018 male with secondary ed', '2018 fem labor', '2018 male labor'] #check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all '..' with None\n",
    "df = df.replace({'..':None})\n",
    "#replace all NaN with None\n",
    "final_df=df.where((pd.notnull(df)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save processed dataset to csv\n",
    "processed_data_file = data_dir+dataset_name+'_edit.csv'\n",
    "final_df.to_csv(processed_data_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload processed data to Carto\n",
    "print('Uploading processed data to Carto.')\n",
    "#set up carto authentication using local variables for username (CARTO_WRI_RW_USER) and API key (CARTO_WRI_RW_KEY)\n",
    "auth_client = APIKeyAuthClient(api_key=os.getenv('CARTO_WRI_RW_KEY'), base_url=\"https://{user}.carto.com/\".format(user=os.getenv('CARTO_WRI_RW_USER')))\n",
    "print (os.getenv('CARTO_WRI_RW_KEY'))\n",
    "#set up dataset manager with authentication\n",
    "dataset_manager = DatasetManager(auth_client)\n",
    "#upload dataset to carto\n",
    "dataset = dataset_manager.create(processed_data_file)\n",
    "print('Carto table created: {}'.format(os.path.basename(processed_data_file).split('.')[0]))\n",
    "#set dataset privacy to 'Public with link'\n",
    "dataset.privacy = 'LINK'\n",
    "dataset.save()\n",
    "print('Privacy set to public with link.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload original data and processed data to Amazon S3 storage\n",
    "def upload_to_aws(local_file, bucket, s3_file):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=os.getenv('aws_access_key_id'), aws_secret_access_key=os.getenv('aws_secret_access_key'))\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        print(\"Upload Successful\")\n",
    "        print(\"http://{}.s3.amazonaws.com/{}\".format(bucket, s3_file))\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "print('Uploading original data to S3.')\n",
    "# Get name of original file from download url.\n",
    "raw_data_file = data_dir+os.path.basename(url)\n",
    "\n",
    "# Copy the raw data into a zipped file to upload to S3\n",
    "raw_data_dir = data_dir+dataset_name+'.zip'\n",
    "\n",
    "with ZipFile(raw_data_dir,'w') as zip:\n",
    "    zip.write(raw_data_file, os.path.basename(raw_data_file))\n",
    "    \n",
    "# Upload raw data file to S3\n",
    "uploaded = upload_to_aws(raw_data_dir, 'wri-public-data', 'resourcewatch/'+os.path.basename(raw_data_dir))\n",
    "\n",
    "print('Uploading processed data to S3.')\n",
    "# Copy the processed data into a zipped file to upload to S3\n",
    "processed_data_dir = data_dir+dataset_name+'_edit'+'.zip'\n",
    "with ZipFile(processed_data_dir,'w') as zip:\n",
    "    zip.write(processed_data_file, os.path.basename(processed_data_file))\n",
    "\n",
    "# Upload processed data file to S3\n",
    "uploaded = upload_to_aws(processed_data_dir, 'wri-public-data', 'resourcewatch/'+os.path.basename(processed_data_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
